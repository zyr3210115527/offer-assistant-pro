import streamlit as st
import os
import base64
import glob
import time
import uuid
import io
from PIL import Image  # ç”¨äºå›¾ç‰‡å‹ç¼©
from openai import OpenAI
import chromadb
from sentence_transformers import SentenceTransformer
NUMBER = 5

# âœ… æ”¹ä¸ºä»é…ç½®æ–‡ä»¶è¯»å–
try:
    api_key = st.secrets["ZHIPU_API_KEY"]
except FileNotFoundError:
    api_key = os.environ.get("ZHIPU_API_KEY", "")
if not api_key:
    st.error("è¯·é…ç½® API Keyï¼å¯ä»¥åœ¨ .streamlit/secrets.toml ä¸­é…ç½®ã€‚")
    st.stop()

client = OpenAI(
    api_key=api_key,
    base_url="https://open.bigmodel.cn/api/paas/v4"
)
st.set_page_config(page_title="Offeré€‰å¤§ç±³åŠ©æ‰‹ Pro", layout="wide")
# ğŸ”´ è¯·åœ¨æ­¤å¤„å¡«å…¥ä½ çš„ Key
client = OpenAI(
    api_key=api_key,
    base_url="https://open.bigmodel.cn/api/paas/v4"
)
MODEL_NAME = "glm-4.6v-flashx"  

# å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
IMAGE_FOLDER = "./images"
DB_PATH = "./chroma_db"


# ================= åˆå§‹åŒ–æ¨¡å‹ä¸æ•°æ®åº“ =================

@st.cache_resource
def load_embed_model():
    # å¦‚æœæƒ³å®Œå…¨ç¦»çº¿ï¼Œè¯·æŠŠ 'BAAI/bge-m3' æ”¹ä¸ºæœ¬åœ°ç»å¯¹è·¯å¾„
    print("æ­£åœ¨åŠ è½½æœ¬åœ° Embedding æ¨¡å‹ (BGE-M3)...")
    return SentenceTransformer('BAAI/bge-m3')


embed_model = load_embed_model()

# åˆå§‹åŒ– ChromaDB
chroma_client = chromadb.PersistentClient(path=DB_PATH)
collection = chroma_client.get_or_create_collection(name="offer_rag_collection")


# ================= æ ¸å¿ƒå·¥å…·å‡½æ•° =================

def encode_image(image_path, max_size=1024):
    """
    ã€æ ¸å¿ƒä¿®å¤ã€‘å›¾ç‰‡å‹ç¼©å‡½æ•°
    å°†å›¾ç‰‡é•¿è¾¹å‹ç¼©åˆ° 1024px ä»¥å†…ï¼Œé˜²æ­¢æŠ¥ Error 400 (Tokenè¶…é™)
    """
    try:
        with Image.open(image_path) as img:
            # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœæ˜¯ RGBA (é€æ˜åº•)ï¼Œè½¬æˆ RGB
            if img.mode in ('RGBA', 'P'):
                img = img.convert('RGB')

            # è®¡ç®—å‹ç¼©æ¯”ä¾‹
            width, height = img.size
            if max(width, height) > max_size:
                scale = max_size / max(width, height)
                new_width = int(width * scale)
                new_height = int(height * scale)
                img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)

            # è½¬ä¸º Base64
            buffered = io.BytesIO()
            img.save(buffered, format="JPEG", quality=85)
            return base64.b64encode(buffered.getvalue()).decode('utf-8')

    except Exception as e:
        print(f"å›¾ç‰‡å‹ç¼©å¤±è´¥: {e}ï¼Œå°è¯•ä½¿ç”¨åŸå›¾...")
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')


def get_embedding(text):
    return embed_model.encode(text).tolist()


def analyze_image_content(image_path):
    """
    ã€å»ºåº“ Promptï¼šæ¸…æ´—ç‰ˆã€‘
    æå–çº¯å‡€çš„ JSON æ•°æ®ï¼Œè¿‡æ»¤æ‰ç”¨æˆ·çš„ä¸ªäººåºŸè¯ï¼ˆå¦‚â€œæœ¬äººæ­å·äººâ€ï¼‰ã€‚
    """
    base64_img = encode_image(image_path)
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text",
                         "text": """
                         ä½ æ˜¯ä¸€ä¸ªæ•°æ®æå–å™¨ã€‚è¿™å¼ å›¾åŒ…å«ç”¨æˆ·çš„Offerä¿¡æ¯ï¼Œä½†ä¹ŸåŒ…å«æ— å…³çš„ä¸ªäººèƒŒæ™¯ï¼ˆå¦‚â€œæœ¬äººæŸåœ°äººâ€ã€â€œçº ç»“ä¸­â€ï¼‰ã€‚
                         ä½ çš„ä»»åŠ¡æ˜¯åªæå– Offer é‡Œçš„ç¡¬æ ¸æ•°æ®ã€‚

                         è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼ˆä¸è¦è¾“å‡º Markdown ä»£ç å—ï¼Œåªè¾“å‡ºçº¯ JSON å­—ç¬¦ä¸²ï¼‰ï¼š
                         {
                            "source_file": "æ–‡ä»¶å",
                            "offers": [
                                {
                                    "company": "å…¬å¸åç§°",
                                    "department": "éƒ¨é—¨/å²—ä½",
                                    "location": "å·¥ä½œåœ°ç‚¹(Base)",
                                    "salary": "è–ªèµ„å…¬å¼(å¦‚(n+3)*16ï¼ŒåŸæ ·æ‘˜å½•)",
                                    "welfare": "ç­¾å­—è´¹/æˆ¿è¡¥/å…¬ç§¯é‡‘ç­‰",
                                    "pros_cons": "åŸæ–‡æåˆ°çš„ä¼˜ç¼ºç‚¹"
                                }
                            ]
                         }
                         """},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_img}"}}
                    ]
                }
            ],
            top_p=0.1,  # æä½éšæœºæ€§ï¼Œä¿è¯æ ¼å¼ç¨³å®š
            temperature=0.1
        )
        # æ¸…ç†å¯èƒ½å­˜åœ¨çš„ markdown ç¬¦å·
        content = response.choices[0].message.content
        content = content.replace("```json", "").replace("```", "").strip()
        return content
    except Exception as e:
        print(f"è§£æå›¾ç‰‡å¤±è´¥ {image_path}: {e}")
        return ""


def build_database():
    """å»ºåº“æµç¨‹ï¼ˆæ”¯æŒå¢é‡æ›´æ–°ï¼‰"""
    if not os.path.exists(IMAGE_FOLDER):
        os.makedirs(IMAGE_FOLDER)
        st.error(f"è¯·å…ˆå»ºç«‹ {IMAGE_FOLDER} æ–‡ä»¶å¤¹å¹¶æ”¾å…¥å›¾ç‰‡ï¼")
        return

    image_files = glob.glob(os.path.join(IMAGE_FOLDER, "*.*"))

    # 1. å¢é‡æ£€æŸ¥
    existing_data = collection.get()
    existing_paths = set()
    if existing_data and existing_data['metadatas']:
        for meta in existing_data['metadatas']:
            existing_paths.add(meta['image_path'])

    files_to_add = [f for f in image_files if f.lower().endswith(('.png', '.jpg', '.jpeg')) and f not in existing_paths]

    if not files_to_add:
        st.info("ğŸ“š æ•°æ®åº“å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°ã€‚")
        return

    # 2. å¼€å§‹å¤„ç†
    progress_bar = st.progress(0)
    status_text = st.empty()

    ids = []
    embeddings = []
    metadatas = []
    new_count = 0

    for i, img_path in enumerate(files_to_add):
        status_text.text(f"æ­£åœ¨æ¸…æ´—å¹¶å…¥åº“: {os.path.basename(img_path)} ...")

        # è·å–æ¸…æ´—åçš„ JSON æ–‡æœ¬
        caption = analyze_image_content(img_path)
        if not caption: continue

        ids.append(str(uuid.uuid4()))
        embeddings.append(get_embedding(caption))
        metadatas.append({"image_path": img_path, "caption": caption})

        new_count += 1
        progress_bar.progress((i + 1) / len(files_to_add))

    if ids:
        collection.add(ids=ids, embeddings=embeddings, metadatas=metadatas)
        st.success(f"ğŸ‰ æ›´æ–°å®Œæˆï¼æ¸…æ´—å¹¶å­˜å…¥äº† {new_count} å¼  Offer æ•°æ®ã€‚")
        time.sleep(1)

    status_text.empty()
    progress_bar.empty()


def chat_pipeline(user_query):
    """
    ã€RAG ç²¾å‡†ç‹™å‡»ç‰ˆã€‘ï¼šç™½åå•è¿‡æ»¤ + å¼ºåˆ¶Markdownæ ¼å¼ä¿®å¤
    åªå›ç­”ç”¨æˆ·ç‚¹åçš„å…¬å¸ï¼Œå‰”é™¤æ— å…³å¹²æ‰°é¡¹ã€‚
    """
    print(f"\næ­£åœ¨æ€è€ƒé—®é¢˜: {user_query} ...")

    query_vec = get_embedding(user_query)
    results = collection.query(query_embeddings=[query_vec], n_results=NUMBER)

    if not results['metadatas'] or not results['metadatas'][0]:
        return "æ•°æ®åº“é‡Œå¥½åƒæ²¡æœ‰ç›¸å…³çš„ Offer å›¾ç‰‡ã€‚", []

    content = []
    retrieved_items = results['metadatas'][0]
    display_images = []
    MAX_IMAGES_TO_LLM = 5

    context_str_list = []

    # === 1. æ„å»ºç™½åå• (White-List) ===
    # å®šä¹‰æˆ‘ä»¬å…³æ³¨çš„æ‰€æœ‰å¤§å‚å…³é”®è¯
    known_companies = ["å¿«æ‰‹", "å­—èŠ‚", "è…¾è®¯", "é˜¿é‡Œ", "èš‚èš", "ç¾å›¢", "æ‹¼å¤šå¤š", "åä¸º", "ç™¾åº¦", "å°çº¢ä¹¦", "äº¬ä¸œ",
                       "ç½‘æ˜“","è®¯é£","æ»´æ»´"]

    # æ‰¾å‡ºç”¨æˆ·é—®å¥é‡Œæåˆ°çš„å…¬å¸
    target_companies = [c for c in known_companies if c in user_query]

    # ç”Ÿæˆè¿‡æ»¤æŒ‡ä»¤
    if target_companies:
        # å¦‚æœç”¨æˆ·æ˜ç¡®æåˆ°äº†å…¬å¸åï¼ˆå¦‚â€œå­—èŠ‚ã€å¿«æ‰‹â€ï¼‰ï¼Œå¼€å¯ä¸¥æ ¼è¿‡æ»¤æ¨¡å¼
        filter_instruction = f"""
        âš ï¸ã€ä¸¥æ ¼è¿‡æ»¤æŒ‡ä»¤ã€‘
        ç”¨æˆ·åªå¯¹ä»¥ä¸‹å…¬å¸æ„Ÿå…´è¶£ï¼šã€{'ã€'.join(target_companies)}ã€‘ã€‚
        è¯·æ‰§è¡Œâ€œç™½åå•è¿‡æ»¤â€ï¼š
        1. ä»”ç»†é˜…è¯»ä¸‹æ–¹æ•°æ®æºã€‚
        2. å¦‚æœæ•°æ®æºé‡Œçš„ Offer å±äºä¸Šè¿°åå•ï¼Œè¯·æå–ã€‚
        3. å¦‚æœæ•°æ®æºæ˜¯â€œé˜¿é‡Œâ€ã€â€œæ‹¼å¤šå¤šâ€ã€â€œèš‚èšâ€ç­‰**ä¸åœ¨åå•å†…**çš„å…¬å¸ï¼Œç›´æ¥å¿½ç•¥ï¼Œ**ä¸¥ç¦**å†™å…¥è¡¨æ ¼ï¼
        4. è¡¨æ ¼é‡Œåªèƒ½å‡ºç°ï¼š{'ã€'.join(target_companies)}ã€‚
        """
    else:
        # å¦‚æœç”¨æˆ·æ²¡æå…·ä½“å…¬å¸ï¼ˆå¦‚â€œå¸®æˆ‘å¯¹æ¯”ä¸€ä¸‹åº“é‡Œçš„Offerâ€ï¼‰ï¼Œåˆ™ä¸è¿‡æ»¤
        filter_instruction = "ç”¨æˆ·æœªæŒ‡å®šå…·ä½“å…¬å¸ï¼Œè¯·åˆ—å‡ºæ‰€æœ‰æ£€ç´¢åˆ°çš„é«˜è´¨é‡ Offerã€‚"

    # === 2. ç»„è£…æ•°æ® ===
    for i, item in enumerate(retrieved_items):
        try:
            img_path = item["image_path"]
            json_data = item["caption"]

            display_images.append(img_path)

            # è°ƒè¯•æ˜¾ç¤º
            #st.write(f"#### ğŸ•µï¸â€â™‚ï¸ æ•°æ®æº {i + 1}ï¼š")
            #with st.expander("æŸ¥çœ‹åŸå§‹ JSON"):
            #    st.code(json_data, language='json')

            if i < MAX_IMAGES_TO_LLM:
                base64_img = encode_image(img_path)
                content.append({
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{base64_img}"}
                })
                context_str_list.append(f"== æ•°æ®æº {i + 1} (å«å›¾) ==\n{json_data}")
            else:
                context_str_list.append(f"== æ•°æ®æº {i + 1} (ä»…æ–‡æœ¬) ==\n{json_data}")

        except Exception as e:
            print(f"å¤„ç†æ£€ç´¢ç»“æœ {i} å‡ºé”™: {e}")

    full_context = "\n\n".join(context_str_list)

    # === 3. æœ€ç»ˆ Prompt ===
    prompt_text = f"""
    ç”¨æˆ·é—®é¢˜ï¼š"{user_query}"

    {filter_instruction}

    æˆ‘æä¾›äº† {len(retrieved_items)} ä»½ Offer æ•°æ®ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚è¾“å‡ºã€‚

    **è¦æ±‚ä¸€ï¼šè¾“å‡ºè¡¨æ ¼ (Markdown)**
    å¿…é¡»è¾“å‡ºæ ‡å‡†çš„ Markdown è¡¨æ ¼ï¼Œæ ¼å¼å¦‚ä¸‹ï¼ˆä¸è¦åˆå¹¶å•å…ƒæ ¼ï¼Œæ¯ä¸€è¡Œå¯¹åº”ä¸€ä¸ªOfferï¼‰ï¼š
    | å…¬å¸ | éƒ¨é—¨/å²—ä½ | åœ°ç‚¹ | è–ªèµ„å…¬å¼ | æ€»åŒ…ä¼°ç®— | ä¼˜ç¼ºç‚¹ |
    |---|---|---|---|---|---|
    | ... | ... | ... | ... | ... | ... |

    **è¦æ±‚äºŒï¼šå†…å®¹æ¸…æ´—**
    - è–ªèµ„å…¬å¼ï¼šåŸæ ·æ‘˜å½• JSON é‡Œçš„å…¬å¼ï¼ˆå¦‚ `(n+3)*16`ï¼‰ã€‚
    - æ€»åŒ…ä¼°ç®—ï¼šå¦‚æœ n æœªçŸ¥ï¼Œä¿ç•™ n çš„å…¬å¼å½¢å¼ã€‚
    - ä¼˜ç¼ºç‚¹ï¼šç²¾ç®€æå–ï¼Œä¸è¦é•¿ç¯‡å¤§è®ºã€‚

    **è¦æ±‚ä¸‰ï¼šæœ€ç»ˆå»ºè®®**
    é’ˆå¯¹ç”¨æˆ·ç‚¹åçš„è¿™å‡ å®¶å…¬å¸ï¼Œç»™å‡ºä¸€å¥ç®€çŸ­çš„é€‰æ‹©å»ºè®®ã€‚

    === å¾…å¤„ç†æ•°æ®æº ===
    {full_context}
    """

    content.append({"type": "text", "text": prompt_text})

    final_response = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªåªå¬æŒ‡ä»¤çš„æ•°æ®åˆ†æå¸ˆï¼Œä¸¥æ ¼æ‰§è¡Œè¿‡æ»¤è¦æ±‚ã€‚"},
            {"role": "user", "content": content}
        ],
        stream=False,
        top_p=0.2,
        temperature=0.1
    )

    return final_response.choices[0].message.content, display_images

# ================= Streamlit ä¸»ç¨‹åº =================
def main():
    st.title("ğŸ’° AI Offer é€‰å¤§ç±³åŠ©æ‰‹ Pro")

    with st.sidebar:
        st.header("âš™ï¸ æ§åˆ¶å°")
        if st.button("ğŸ”„ è¯»å–æ–°å›¾ç‰‡å¹¶æ›´æ–°åº“"):
            with st.spinner("æ­£åœ¨å‹ç¼©å›¾ç‰‡å¹¶æ¸…æ´—æ•°æ®ï¼Œè¯·ç¨å€™..."):
                build_database()

        st.info(f"æ¯æ¬¡æ£€ç´¢ {NUMBER} å¼ æœ€ç›¸å…³çš„ Offer")
        st.caption("æç¤ºï¼šåˆæ¬¡è¿è¡Œè¯·å…ˆç‚¹å‡»æ›´æ–°åº“")

    # åˆå§‹åŒ–èŠå¤©å†å²
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # æ˜¾ç¤ºå†å²æ¶ˆæ¯
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # å¤„ç†è¾“å…¥
    if prompt := st.chat_input("è¯·è¾“å…¥é—®é¢˜ (ä¾‹å¦‚: å¯¹æ¯”ä¸€ä¸‹å­—èŠ‚å’Œå¿«æ‰‹ï¼Œç®—ä¸€ä¸‹æ€»åŒ…)"):
        st.chat_message("user").markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.chat_message("assistant"):
            with st.status("ğŸ§  AI æ­£åœ¨æ£€ç´¢å¹¶ç–¯ç‹‚è®¡ç®—ä¸­...", expanded=True) as status:
                try:
                    answer, ref_images = chat_pipeline(prompt)

                    if ref_images:
                        st.write(f"ğŸ” æ£€ç´¢åˆ° {len(ref_images)} å¼ ç›¸å…³ Offerï¼š")
                        cols = st.columns(len(ref_images))
                        for idx, img_path in enumerate(ref_images):
                            # ä½¿ç”¨ use_container_width=True ä¿®å¤å¸ƒå±€æŠ¥é”™
                            cols[idx].image(img_path, caption=f"Offer {idx + 1}", width='content')

                    status.update(label="åˆ†æå®Œæˆï¼", state="complete", expanded=False)
                    st.markdown(answer)
                    st.session_state.messages.append({"role": "assistant", "content": answer})

                except Exception as e:
                    st.error(f"å‘ç”Ÿé”™è¯¯: {e}")


if __name__ == "__main__":
    main()